{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hHxp3iELB4Q",
        "outputId": "a00dce83-3238-401f-8f24-91e2206ce59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2jKwCV4sra8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnykGdyYMCoJ"
      },
      "source": [
        "Создание датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZudowgBXLGJC"
      },
      "outputs": [],
      "source": [
        "#функция для чтения json\n",
        "def load_rows(filepath, nrows = None):\n",
        "    with open(filepath, encoding='utf-8') as json_file:\n",
        "        count = 0\n",
        "        objs = []\n",
        "        line = json_file.readline()\n",
        "        while (nrows is None or count < nrows) and line:\n",
        "            count += 1\n",
        "            obj = json.loads(line)\n",
        "            objs.append(obj)\n",
        "            line = json_file.readline()\n",
        "        return pd.DataFrame(objs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "6x7AmPjkLJOV",
        "outputId": "1007654c-404a-4141-d4a7-7cfcfd8cf455"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b4aa5084-3650-4d2a-aded-9100b525e04b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>photo_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>caption</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200100</td>\n",
              "      <td>200100</td>\n",
              "      <td>200100</td>\n",
              "      <td>200100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>200098</td>\n",
              "      <td>36680</td>\n",
              "      <td>76413</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>_CYoxbCIKuAwpq4crHCPWg</td>\n",
              "      <td>FEXhWNCMkv22qG04E83Qjg</td>\n",
              "      <td></td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>2</td>\n",
              "      <td>528</td>\n",
              "      <td>103366</td>\n",
              "      <td>108152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4aa5084-3650-4d2a-aded-9100b525e04b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4aa5084-3650-4d2a-aded-9100b525e04b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4aa5084-3650-4d2a-aded-9100b525e04b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                      photo_id             business_id caption   label\n",
              "count                   200100                  200100  200100  200100\n",
              "unique                  200098                   36680   76413       5\n",
              "top     _CYoxbCIKuAwpq4crHCPWg  FEXhWNCMkv22qG04E83Qjg            food\n",
              "freq                         2                     528  103366  108152"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#download photos.json as dataframe\n",
        "photos = load_rows('/content/drive/My Drive/yelp/photos.json')\n",
        "photos.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "7oFF1ib6LLmC",
        "outputId": "6fed7ca8-a33e-43f9-f794-00ebb2a1427a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-53caa6c5-915e-4c4f-a345-c52126ef8a88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>photo_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>caption</th>\n",
              "      <th>label</th>\n",
              "      <th>photo_path</th>\n",
              "      <th>photo_paths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zsvj7vloL4L5jhYyPIuVwg</td>\n",
              "      <td>Nk-SJhPlDBkAZvfsADtccA</td>\n",
              "      <td>Nice rock artwork everywhere and craploads of ...</td>\n",
              "      <td>inside</td>\n",
              "      <td>zsvj7vloL4L5jhYyPIuVwg.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/zsvj7vloL4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HCUdRJHHm_e0OCTlZetGLg</td>\n",
              "      <td>yVZtL5MmrpiivyCIrVkGgA</td>\n",
              "      <td></td>\n",
              "      <td>outside</td>\n",
              "      <td>HCUdRJHHm_e0OCTlZetGLg.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/HCUdRJHHm_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>vkr8T0scuJmGVvN2HJelEA</td>\n",
              "      <td>_ab50qdWOk0DdB6XOrBitw</td>\n",
              "      <td>oyster shooter</td>\n",
              "      <td>drink</td>\n",
              "      <td>vkr8T0scuJmGVvN2HJelEA.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/vkr8T0scuJ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pve7D6NUrafHW3EAORubyw</td>\n",
              "      <td>SZU9c8V2GuREDN5KgyHFJw</td>\n",
              "      <td>Shrimp scampi</td>\n",
              "      <td>food</td>\n",
              "      <td>pve7D6NUrafHW3EAORubyw.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/pve7D6NUra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H52Er-uBg6rNrHcReWTD2w</td>\n",
              "      <td>Gzur0f0XMkrVxIwYJvOt2g</td>\n",
              "      <td></td>\n",
              "      <td>food</td>\n",
              "      <td>H52Er-uBg6rNrHcReWTD2w.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/H52Er-uBg6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53caa6c5-915e-4c4f-a345-c52126ef8a88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53caa6c5-915e-4c4f-a345-c52126ef8a88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53caa6c5-915e-4c4f-a345-c52126ef8a88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 photo_id             business_id  \\\n",
              "0  zsvj7vloL4L5jhYyPIuVwg  Nk-SJhPlDBkAZvfsADtccA   \n",
              "1  HCUdRJHHm_e0OCTlZetGLg  yVZtL5MmrpiivyCIrVkGgA   \n",
              "2  vkr8T0scuJmGVvN2HJelEA  _ab50qdWOk0DdB6XOrBitw   \n",
              "3  pve7D6NUrafHW3EAORubyw  SZU9c8V2GuREDN5KgyHFJw   \n",
              "4  H52Er-uBg6rNrHcReWTD2w  Gzur0f0XMkrVxIwYJvOt2g   \n",
              "\n",
              "                                             caption    label  \\\n",
              "0  Nice rock artwork everywhere and craploads of ...   inside   \n",
              "1                                                     outside   \n",
              "2                                     oyster shooter    drink   \n",
              "3                                      Shrimp scampi     food   \n",
              "4                                                        food   \n",
              "\n",
              "                   photo_path  \\\n",
              "0  zsvj7vloL4L5jhYyPIuVwg.jpg   \n",
              "1  HCUdRJHHm_e0OCTlZetGLg.jpg   \n",
              "2  vkr8T0scuJmGVvN2HJelEA.jpg   \n",
              "3  pve7D6NUrafHW3EAORubyw.jpg   \n",
              "4  H52Er-uBg6rNrHcReWTD2w.jpg   \n",
              "\n",
              "                                         photo_paths  \n",
              "0  /content/drive/My Drive/yelp/photos/zsvj7vloL4...  \n",
              "1  /content/drive/My Drive/yelp/photos/HCUdRJHHm_...  \n",
              "2  /content/drive/My Drive/yelp/photos/vkr8T0scuJ...  \n",
              "3  /content/drive/My Drive/yelp/photos/pve7D6NUra...  \n",
              "4  /content/drive/My Drive/yelp/photos/H52Er-uBg6...  "
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Add photo path\n",
        "\n",
        "photos['photo_path'] = photos['photo_id'] + '.jpg'\n",
        "photos['photo_paths'] = '/content/drive/My Drive/yelp/photos/' + photos['photo_path']\n",
        "photos.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 39,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "ESYGhvHotaOC",
        "outputId": "a911ec10-f433-4da8-b908-f8923af0eac0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d360c1b5-87d8-4771-a012-9343d4c6ec30\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d360c1b5-87d8-4771-a012-9343d4c6ec30\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "uploaded = files.upload()\n",
        "                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKnk49TJLTB0"
      },
      "outputs": [],
      "source": [
        "#Shuffling and getting rid of menu label\n",
        "photos = pd.concat([photos[photos['label']=='food'][:12000],photos[photos['label']=='inside'][:12000],\n",
        "                        photos[photos['label']=='outside'][:12000], photos[photos['label']=='drink'][:12000]])\n",
        "photos = photos.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPvfP-nDMJQj",
        "outputId": "9a7c0f98-6472-4b42-a95a-77b5ba817a64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "outside    12000\n",
              "inside     12000\n",
              "food       12000\n",
              "drink      12000\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "photos['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "70qsyLZiMJ1Y",
        "outputId": "848f6914-0350-49de-de6e-4312b6330d89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5d1e973c-9a46-4825-914d-f2ded6c2167f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_count</th>\n",
              "      <th>is_open</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150346.000000</td>\n",
              "      <td>150346.000000</td>\n",
              "      <td>150346.000000</td>\n",
              "      <td>150346.000000</td>\n",
              "      <td>150346.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>36.671150</td>\n",
              "      <td>-89.357339</td>\n",
              "      <td>3.596724</td>\n",
              "      <td>44.866561</td>\n",
              "      <td>0.79615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.872759</td>\n",
              "      <td>14.918502</td>\n",
              "      <td>0.974421</td>\n",
              "      <td>121.120136</td>\n",
              "      <td>0.40286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>27.555127</td>\n",
              "      <td>-120.095137</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>32.187293</td>\n",
              "      <td>-90.357810</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>38.777413</td>\n",
              "      <td>-86.121179</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>39.954036</td>\n",
              "      <td>-75.421542</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>53.679197</td>\n",
              "      <td>-73.200457</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7568.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d1e973c-9a46-4825-914d-f2ded6c2167f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d1e973c-9a46-4825-914d-f2ded6c2167f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d1e973c-9a46-4825-914d-f2ded6c2167f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            latitude      longitude          stars   review_count  \\\n",
              "count  150346.000000  150346.000000  150346.000000  150346.000000   \n",
              "mean       36.671150     -89.357339       3.596724      44.866561   \n",
              "std         5.872759      14.918502       0.974421     121.120136   \n",
              "min        27.555127    -120.095137       1.000000       5.000000   \n",
              "25%        32.187293     -90.357810       3.000000       8.000000   \n",
              "50%        38.777413     -86.121179       3.500000      15.000000   \n",
              "75%        39.954036     -75.421542       4.500000      37.000000   \n",
              "max        53.679197     -73.200457       5.000000    7568.000000   \n",
              "\n",
              "            is_open  \n",
              "count  150346.00000  \n",
              "mean        0.79615  \n",
              "std         0.40286  \n",
              "min         0.00000  \n",
              "25%         1.00000  \n",
              "50%         1.00000  \n",
              "75%         1.00000  \n",
              "max         1.00000  "
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#download json as dataframe\n",
        "business = load_rows('/content/drive/My Drive/yelp/yelp_academic_dataset_business.json')\n",
        "business.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RE9bJXmiMOkp",
        "outputId": "dc5ad1f7-7455-4fa4-cd59-17a64869542b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ed6a63f8-3767-48dc-a7da-8aba2dcc19b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>photo_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>caption</th>\n",
              "      <th>label</th>\n",
              "      <th>photo_path</th>\n",
              "      <th>photo_paths</th>\n",
              "      <th>name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oEawexb8NqKtwHo9YWXIHg</td>\n",
              "      <td>6Ty-KKWq6hLZYW8DWEHYvg</td>\n",
              "      <td></td>\n",
              "      <td>outside</td>\n",
              "      <td>oEawexb8NqKtwHo9YWXIHg.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/oEawexb8Nq...</td>\n",
              "      <td>Pat O'Brien’s</td>\n",
              "      <td>{'Caters': 'False', 'Alcohol': 'u'full_bar'', ...</td>\n",
              "      <td>American (Traditional), Arts &amp; Entertainment, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>egVTgNRoHJpai8tmfRNK5A</td>\n",
              "      <td>6Ty-KKWq6hLZYW8DWEHYvg</td>\n",
              "      <td></td>\n",
              "      <td>drink</td>\n",
              "      <td>egVTgNRoHJpai8tmfRNK5A.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/egVTgNRoHJ...</td>\n",
              "      <td>Pat O'Brien’s</td>\n",
              "      <td>{'Caters': 'False', 'Alcohol': 'u'full_bar'', ...</td>\n",
              "      <td>American (Traditional), Arts &amp; Entertainment, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>l_feMPSsRxr4Urdge1xGrw</td>\n",
              "      <td>6Ty-KKWq6hLZYW8DWEHYvg</td>\n",
              "      <td>Me &amp; fraaaands! :)</td>\n",
              "      <td>outside</td>\n",
              "      <td>l_feMPSsRxr4Urdge1xGrw.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/l_feMPSsRx...</td>\n",
              "      <td>Pat O'Brien’s</td>\n",
              "      <td>{'Caters': 'False', 'Alcohol': 'u'full_bar'', ...</td>\n",
              "      <td>American (Traditional), Arts &amp; Entertainment, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ie6WqVf62mRyAMKsSWBzvw</td>\n",
              "      <td>6Ty-KKWq6hLZYW8DWEHYvg</td>\n",
              "      <td></td>\n",
              "      <td>inside</td>\n",
              "      <td>ie6WqVf62mRyAMKsSWBzvw.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/ie6WqVf62m...</td>\n",
              "      <td>Pat O'Brien’s</td>\n",
              "      <td>{'Caters': 'False', 'Alcohol': 'u'full_bar'', ...</td>\n",
              "      <td>American (Traditional), Arts &amp; Entertainment, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1MRED2kKUxboJ8OpYhAHaw</td>\n",
              "      <td>6Ty-KKWq6hLZYW8DWEHYvg</td>\n",
              "      <td></td>\n",
              "      <td>drink</td>\n",
              "      <td>1MRED2kKUxboJ8OpYhAHaw.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/1MRED2kKUx...</td>\n",
              "      <td>Pat O'Brien’s</td>\n",
              "      <td>{'Caters': 'False', 'Alcohol': 'u'full_bar'', ...</td>\n",
              "      <td>American (Traditional), Arts &amp; Entertainment, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47995</th>\n",
              "      <td>a22wunluf6mFC3Uzf8H8Xg</td>\n",
              "      <td>WqSck6AHitsxVw56_aZLPQ</td>\n",
              "      <td>Flicks + Food Trucks</td>\n",
              "      <td>inside</td>\n",
              "      <td>a22wunluf6mFC3Uzf8H8Xg.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/a22wunluf6...</td>\n",
              "      <td>Krepelicious Food Truck</td>\n",
              "      <td>{'Alcohol': 'u'none'', 'RestaurantsTakeOut': '...</td>\n",
              "      <td>Food, Street Vendors, Food Trucks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47996</th>\n",
              "      <td>_LUq4vP6EQ-NsjProtU0xA</td>\n",
              "      <td>0VlGRVZ2z62KXgZCc7b5Kw</td>\n",
              "      <td></td>\n",
              "      <td>inside</td>\n",
              "      <td>_LUq4vP6EQ-NsjProtU0xA.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/_LUq4vP6EQ...</td>\n",
              "      <td>CC's Coffee House</td>\n",
              "      <td>{'BusinessAcceptsCreditCards': 'True', 'BikePa...</td>\n",
              "      <td>Food, Coffee &amp; Tea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47997</th>\n",
              "      <td>knuRNVIdN_oVTwTORTxGNA</td>\n",
              "      <td>5EQ8WmyskZFjvrlaEbjMZw</td>\n",
              "      <td></td>\n",
              "      <td>drink</td>\n",
              "      <td>knuRNVIdN_oVTwTORTxGNA.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/knuRNVIdN_...</td>\n",
              "      <td>TGI Fridays</td>\n",
              "      <td>{'Ambience': '{'romantic': False, 'intimate': ...</td>\n",
              "      <td>American (New), American (Traditional), Fast F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47998</th>\n",
              "      <td>RYydwjqszamdclCRSxyKvw</td>\n",
              "      <td>0_J_SEJLxSjHcFfGgWeWow</td>\n",
              "      <td></td>\n",
              "      <td>outside</td>\n",
              "      <td>RYydwjqszamdclCRSxyKvw.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/RYydwjqsza...</td>\n",
              "      <td>High Street Caffe</td>\n",
              "      <td>{'RestaurantsReservations': 'True', 'Restauran...</td>\n",
              "      <td>Restaurants, Cajun/Creole, Southern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47999</th>\n",
              "      <td>GeEhVd2gbfSVEra3S2p7Dw</td>\n",
              "      <td>RuEIK45gBF5iDbYoSa9tOA</td>\n",
              "      <td>Somersby Cider. Delicious</td>\n",
              "      <td>drink</td>\n",
              "      <td>GeEhVd2gbfSVEra3S2p7Dw.jpg</td>\n",
              "      <td>/content/drive/My Drive/yelp/photos/GeEhVd2gbf...</td>\n",
              "      <td>The Underground Tap &amp; Grill</td>\n",
              "      <td>{'NoiseLevel': 'u'average'', 'BikeParking': 'F...</td>\n",
              "      <td>American (Traditional), Pubs, Tapas Bars, Rest...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48000 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed6a63f8-3767-48dc-a7da-8aba2dcc19b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed6a63f8-3767-48dc-a7da-8aba2dcc19b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed6a63f8-3767-48dc-a7da-8aba2dcc19b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     photo_id             business_id  \\\n",
              "0      oEawexb8NqKtwHo9YWXIHg  6Ty-KKWq6hLZYW8DWEHYvg   \n",
              "1      egVTgNRoHJpai8tmfRNK5A  6Ty-KKWq6hLZYW8DWEHYvg   \n",
              "2      l_feMPSsRxr4Urdge1xGrw  6Ty-KKWq6hLZYW8DWEHYvg   \n",
              "3      ie6WqVf62mRyAMKsSWBzvw  6Ty-KKWq6hLZYW8DWEHYvg   \n",
              "4      1MRED2kKUxboJ8OpYhAHaw  6Ty-KKWq6hLZYW8DWEHYvg   \n",
              "...                       ...                     ...   \n",
              "47995  a22wunluf6mFC3Uzf8H8Xg  WqSck6AHitsxVw56_aZLPQ   \n",
              "47996  _LUq4vP6EQ-NsjProtU0xA  0VlGRVZ2z62KXgZCc7b5Kw   \n",
              "47997  knuRNVIdN_oVTwTORTxGNA  5EQ8WmyskZFjvrlaEbjMZw   \n",
              "47998  RYydwjqszamdclCRSxyKvw  0_J_SEJLxSjHcFfGgWeWow   \n",
              "47999  GeEhVd2gbfSVEra3S2p7Dw  RuEIK45gBF5iDbYoSa9tOA   \n",
              "\n",
              "                         caption    label                  photo_path  \\\n",
              "0                                 outside  oEawexb8NqKtwHo9YWXIHg.jpg   \n",
              "1                                   drink  egVTgNRoHJpai8tmfRNK5A.jpg   \n",
              "2             Me & fraaaands! :)  outside  l_feMPSsRxr4Urdge1xGrw.jpg   \n",
              "3                                  inside  ie6WqVf62mRyAMKsSWBzvw.jpg   \n",
              "4                                   drink  1MRED2kKUxboJ8OpYhAHaw.jpg   \n",
              "...                          ...      ...                         ...   \n",
              "47995       Flicks + Food Trucks   inside  a22wunluf6mFC3Uzf8H8Xg.jpg   \n",
              "47996                              inside  _LUq4vP6EQ-NsjProtU0xA.jpg   \n",
              "47997                               drink  knuRNVIdN_oVTwTORTxGNA.jpg   \n",
              "47998                             outside  RYydwjqszamdclCRSxyKvw.jpg   \n",
              "47999  Somersby Cider. Delicious    drink  GeEhVd2gbfSVEra3S2p7Dw.jpg   \n",
              "\n",
              "                                             photo_paths  \\\n",
              "0      /content/drive/My Drive/yelp/photos/oEawexb8Nq...   \n",
              "1      /content/drive/My Drive/yelp/photos/egVTgNRoHJ...   \n",
              "2      /content/drive/My Drive/yelp/photos/l_feMPSsRx...   \n",
              "3      /content/drive/My Drive/yelp/photos/ie6WqVf62m...   \n",
              "4      /content/drive/My Drive/yelp/photos/1MRED2kKUx...   \n",
              "...                                                  ...   \n",
              "47995  /content/drive/My Drive/yelp/photos/a22wunluf6...   \n",
              "47996  /content/drive/My Drive/yelp/photos/_LUq4vP6EQ...   \n",
              "47997  /content/drive/My Drive/yelp/photos/knuRNVIdN_...   \n",
              "47998  /content/drive/My Drive/yelp/photos/RYydwjqsza...   \n",
              "47999  /content/drive/My Drive/yelp/photos/GeEhVd2gbf...   \n",
              "\n",
              "                              name  \\\n",
              "0                    Pat O'Brien’s   \n",
              "1                    Pat O'Brien’s   \n",
              "2                    Pat O'Brien’s   \n",
              "3                    Pat O'Brien’s   \n",
              "4                    Pat O'Brien’s   \n",
              "...                            ...   \n",
              "47995      Krepelicious Food Truck   \n",
              "47996            CC's Coffee House   \n",
              "47997                  TGI Fridays   \n",
              "47998            High Street Caffe   \n",
              "47999  The Underground Tap & Grill   \n",
              "\n",
              "                                              attributes  \\\n",
              "0      {'Caters': 'False', 'Alcohol': 'u'full_bar'', ...   \n",
              "1      {'Caters': 'False', 'Alcohol': 'u'full_bar'', ...   \n",
              "2      {'Caters': 'False', 'Alcohol': 'u'full_bar'', ...   \n",
              "3      {'Caters': 'False', 'Alcohol': 'u'full_bar'', ...   \n",
              "4      {'Caters': 'False', 'Alcohol': 'u'full_bar'', ...   \n",
              "...                                                  ...   \n",
              "47995  {'Alcohol': 'u'none'', 'RestaurantsTakeOut': '...   \n",
              "47996  {'BusinessAcceptsCreditCards': 'True', 'BikePa...   \n",
              "47997  {'Ambience': '{'romantic': False, 'intimate': ...   \n",
              "47998  {'RestaurantsReservations': 'True', 'Restauran...   \n",
              "47999  {'NoiseLevel': 'u'average'', 'BikeParking': 'F...   \n",
              "\n",
              "                                              categories  \n",
              "0      American (Traditional), Arts & Entertainment, ...  \n",
              "1      American (Traditional), Arts & Entertainment, ...  \n",
              "2      American (Traditional), Arts & Entertainment, ...  \n",
              "3      American (Traditional), Arts & Entertainment, ...  \n",
              "4      American (Traditional), Arts & Entertainment, ...  \n",
              "...                                                  ...  \n",
              "47995                  Food, Street Vendors, Food Trucks  \n",
              "47996                                 Food, Coffee & Tea  \n",
              "47997  American (New), American (Traditional), Fast F...  \n",
              "47998                Restaurants, Cajun/Creole, Southern  \n",
              "47999  American (Traditional), Pubs, Tapas Bars, Rest...  \n",
              "\n",
              "[48000 rows x 9 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Убираем лишний столбцы, соединяем в один dataframe\n",
        "df = pd.merge(photos, business, how ='inner', on ='business_id')\n",
        "df = df.drop (columns = ['address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars', 'review_count', 'is_open', 'hours'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqz92oklMTBg"
      },
      "outputs": [],
      "source": [
        "# datagen=ImageDataGenerator(rescale=1./255.)\n",
        "# test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "# batch_size = 50\n",
        "# nTrain=48000 \n",
        "# photos_dir = '/content/drive/My Drive/yelp/photos/'\n",
        "\n",
        "\n",
        "# train_generator=datagen.flow_from_dataframe(df[:int(nTrain*0.7)],\n",
        "#                                             photos_dir, x_col = 'photo_path', y_col = 'label',\n",
        "#                                             target_size=(224, 224),\n",
        "#                                             batch_size=batch_size,\n",
        "#                                             class_mode='categorical', subset = 'training',\n",
        "#                                             shuffle=True)\n",
        "# valid_generator=test_datagen.flow_from_dataframe(df[int(nTrain*0.7):int(nTrain*0.9)],\n",
        "#                                                  photos_dir, x_col = 'photo_path', y_col = 'label',\n",
        "#                                                  target_size=(224, 224),\n",
        "#                                                  batch_size=batch_size,\n",
        "#                                                  class_mode='categorical',\n",
        "#                                                  shuffle=True)\n",
        "# test_generator=test_datagen.flow_from_dataframe(df[int(nTrain*0.9):],\n",
        "#                                                 photos_dir, x_col = 'photo_path', y_col = 'label',\n",
        "#                                                 target_size=(224, 224),\n",
        "#                                                 batch_size=batch_size,\n",
        "#                                                 class_mode='categorical',\n",
        "#                                                 shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODb-qv9CMWef"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "# batch_size = 50\n",
        "# nTrain=46000 \n",
        "# test_generator=test_datagen.flow_from_dataframe(photos[int(nTrain*0.9):],\n",
        "#                                                 photos_dir, x_col = 'photo_path', y_col = 'label',\n",
        "#                                                 target_size=(224, 224),\n",
        "#                                                 batch_size=batch_size,\n",
        "#                                                 class_mode='categorical',\n",
        "#                                                 shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCup_eauMen7"
      },
      "outputs": [],
      "source": [
        "# generate batches of train images and labels\n",
        "# nTrain=48000\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# # load the normalized images\n",
        "# datagen = ImageDataGenerator(rescale=1./255, validation_split = 0.2)\n",
        "# # define the batch size\n",
        "# batch_size = 50\n",
        "\n",
        "# # the defined shape is equal to the network output tensor shape\n",
        "# train_features = np.zeros(shape=(nTrain, 7, 7, 512))\n",
        "# train_labels = np.zeros(shape=(nTrain,4))\n",
        "# # generate batches of train images and labels\n",
        "# train_generator = datagen.flow_from_dataframe(photos[:nTrain],\n",
        "#     photos_dir, x_col = 'photo_path', y_col = 'label',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=batch_size,\n",
        "#     class_mode='categorical', subset = 'training',\n",
        "#     shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Chs2XbfMhOb"
      },
      "outputs": [],
      "source": [
        "# # generate batches of validation images and labels\n",
        "# validation_generator = datagen.flow_from_dataframe(photos[:nTrain],\n",
        "#     photos_dir, x_col = 'photo_path', y_col = 'label',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=batch_size,color_mode=\"rgb\",\n",
        "#     class_mode='categorical', subset = 'validation',\n",
        "#     shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEzhIYnlMsiM"
      },
      "outputs": [],
      "source": [
        "# Get feature vector of an image by given model and img_path\n",
        "def getFeatureVector(model, img_path):\n",
        "  img = cv2.imread(img_path) \n",
        "  print(img)\n",
        "  img = cv2.resize(img, (224, 224))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  feature_vector = model.predict(img.reshape(1, 224, 224, 3))\n",
        "  return feature_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raL4iQ0nWvaD"
      },
      "outputs": [],
      "source": [
        "a = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l7n-dwF5nLlA",
        "outputId": "46619dbb-3434-477a-9952-c4d0c8584bda"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/yelp/photos/p4-nbxEdeeoZXf5iIWdL_w.jpg'"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a['photo_paths'][100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91WgxdG5f8O-"
      },
      "outputs": [],
      "source": [
        "k = cv2.imread(a['photo_path'][100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k658ZsJCfl_W"
      },
      "outputs": [],
      "source": [
        "k "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4VMDydCMvKi"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function for get dataframe which contains the output features of given model\n",
        "def getFeatureDataFrame(model):\n",
        "  df = pd.DataFrame(columns=['file', 'features'])\n",
        "  # train_files = train_generator.filepaths\n",
        "  # valid_files = validation_generator.filepaths\n",
        "  # files = photos\n",
        "\n",
        "  df['file'] = a['photo_paths']\n",
        "\n",
        "  df['features'] = df.apply(lambda row: getFeatureVector(model, row['file']), axis=1) \n",
        "  \n",
        "\n",
        "  print(\"All files added.\")\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22NttmKqsJgR"
      },
      "outputs": [],
      "source": [
        "# Get VGG-16 Model\n",
        "def getVGG16Model(lastFourTrainable=False):\n",
        "  vgg_model = VGG16(weights='imagenet', input_shape=input_shape, include_top=True)\n",
        "\n",
        "  # Make all layers untrainable\n",
        "  for layer in vgg_model.layers[:]:\n",
        "      layer.trainable = False\n",
        "\n",
        "  # Add fully connected layer which have 1024 neuron to VGG-16 model\n",
        "  output = vgg_model.get_layer('fc2').output\n",
        "  output = Flatten(name='new_flatten')(output)\n",
        "  output = Dense(units=1024, activation='relu', name='new_fc')(output)\n",
        "  output = Dense(units=4, activation='softmax')(output)\n",
        "  vgg_model = Model(vgg_model.input, output)\n",
        "\n",
        "  # Make last 4 layers trainable if lastFourTrainable == True\n",
        "  if lastFourTrainable == True:\n",
        "    vgg_model.get_layer('block5_conv3').trainable = True\n",
        "    vgg_model.get_layer('fc1').trainable = True\n",
        "    vgg_model.get_layer('fc2').trainable = True\n",
        "    vgg_model.get_layer('new_fc').trainable = True\n",
        "\n",
        "  # Compile VGG-16 model\n",
        "  vgg_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  vgg_model.summary()\n",
        "\n",
        "  return vgg_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIjjVVr977kq"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "img_rows = 224\n",
        "img_cols = 224\n",
        "input_shape = (img_rows,img_cols,3)\n",
        "epochs = 10\n",
        "batch_size = 50\n",
        "num_of_classes = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liF7fK0_1b67"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OksWnqew77nX",
        "outputId": "543b819d-1829-4d9c-92f9-ddb6c039705b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " new_flatten (Flatten)       (None, 4096)              0         \n",
            "                                                                 \n",
            " new_fc (Dense)              (None, 1024)              4195328   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 4100      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,459,972\n",
            "Trainable params: 4,199,428\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get feature extractor model from last layer of vgg_model_a\n",
        "vgg_model_a = getVGG16Model(lastFourTrainable=False)\n",
        "# vgg_model_a.load_weights('/content/drive/MyDrive/Colab Notebooks/cinic-10/model_vgg_nontrainable.h5')\n",
        "feature_model_vgg_a = Model(inputs=vgg_model_a.input, outputs=vgg_model_a.get_layer('new_fc').output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "Ud_XIMXBezRw",
        "outputId": "903bbfa7-56fd-4e97-d157-a45c9dad8467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-cb0edd6ddeb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFeatureDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_model_vgg_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-3eb2169a8bf5>\u001b[0m in \u001b[0;36mgetFeatureDataFrame\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'photo_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetFeatureVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-3eb2169a8bf5>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'photo_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetFeatureVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-6b8a113bdae4>\u001b[0m in \u001b[0;36mgetFeatureVector\u001b[0;34m(model, img_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ],
      "source": [
        "df = getFeatureDataFrame(feature_model_vgg_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "IYX5VkQyaJlW",
        "outputId": "fe1645fd-e9ae-4c53-e380-6ce19f0c5e44"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-4344277883b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHZ0y-PK77qP"
      },
      "outputs": [],
      "source": [
        "df.to_pickle(\"features_vgg_a.pickle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "UYcQx6U18FqC",
        "outputId": "91c4b139-a63e-45b4-bdc8-676cfedb9eac"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-4648b138c737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'photo_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'photo_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/для диплома/photos/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'photo_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'photo_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for row in df.itertuples():\n",
        "  df['photo_id'][row.Index] = str(df['photo_id'][row.Index]).replace(\"/content/drive/MyDrive/для диплома/photos/\",\"\")\n",
        "  df['photo_id'][row.Index] = str(df['photo_id'][row.Index]).replace(\".jpg\",\"\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1sjrjZjv8Fsb",
        "outputId": "4ea5334a-aca3-4930-ce2a-fe19a160a91f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2f9eb48b-e21e-438e-91b2-85e873655af7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>photo_id</th>\n",
              "      <th>business_id_x</th>\n",
              "      <th>caption_x</th>\n",
              "      <th>label_x</th>\n",
              "      <th>photo_path_x</th>\n",
              "      <th>name</th>\n",
              "      <th>attributes</th>\n",
              "      <th>categories</th>\n",
              "      <th>business_id_y</th>\n",
              "      <th>caption_y</th>\n",
              "      <th>label_y</th>\n",
              "      <th>photo_path_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9wTk1j-bB5UN17uiOeO9KA</td>\n",
              "      <td>EEVFMbJ6_YdbP3dHpHzmEg</td>\n",
              "      <td></td>\n",
              "      <td>drink</td>\n",
              "      <td>9wTk1j-bB5UN17uiOeO9KA.jpg</td>\n",
              "      <td>Little Fox</td>\n",
              "      <td>{'BusinessAcceptsBitcoin': 'False', 'Restauran...</td>\n",
              "      <td>Wine Bars, American (New), Restaurants, Bars, ...</td>\n",
              "      <td>EEVFMbJ6_YdbP3dHpHzmEg</td>\n",
              "      <td></td>\n",
              "      <td>drink</td>\n",
              "      <td>9wTk1j-bB5UN17uiOeO9KA.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LDJohic0bTD0oRknayxE1Q</td>\n",
              "      <td>EEVFMbJ6_YdbP3dHpHzmEg</td>\n",
              "      <td></td>\n",
              "      <td>food</td>\n",
              "      <td>LDJohic0bTD0oRknayxE1Q.jpg</td>\n",
              "      <td>Little Fox</td>\n",
              "      <td>{'BusinessAcceptsBitcoin': 'False', 'Restauran...</td>\n",
              "      <td>Wine Bars, American (New), Restaurants, Bars, ...</td>\n",
              "      <td>EEVFMbJ6_YdbP3dHpHzmEg</td>\n",
              "      <td></td>\n",
              "      <td>food</td>\n",
              "      <td>LDJohic0bTD0oRknayxE1Q.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>96Qjf-5y9GVVf_cpZO8AVQ</td>\n",
              "      <td>EEVFMbJ6_YdbP3dHpHzmEg</td>\n",
              "      <td></td>\n",
              "      <td>outside</td>\n",
              "      <td>96Qjf-5y9GVVf_cpZO8AVQ.jpg</td>\n",
              "      <td>Little Fox</td>\n",
              "      <td>{'BusinessAcceptsBitcoin': 'False', 'Restauran...</td>\n",
              "      <td>Wine Bars, American (New), Restaurants, Bars, ...</td>\n",
              "      <td>EEVFMbJ6_YdbP3dHpHzmEg</td>\n",
              "      <td></td>\n",
              "      <td>outside</td>\n",
              "      <td>96Qjf-5y9GVVf_cpZO8AVQ.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IUFL5sUq0Fu7gN79f15EAg</td>\n",
              "      <td>EEVFMbJ6_YdbP3dHpHzmEg</td>\n",
              "      <td></td>\n",
              "      <td>drink</td>\n",
              "      <td>IUFL5sUq0Fu7gN79f15EAg.jpg</td>\n",
              "      <td>Little Fox</td>\n",
              "      <td>{'BusinessAcceptsBitcoin': 'False', 'Restauran...</td>\n",
              "      <td>Wine Bars, American (New), Restaurants, Bars, ...</td>\n",
              "      <td>EEVFMbJ6_YdbP3dHpHzmEg</td>\n",
              "      <td></td>\n",
              "      <td>drink</td>\n",
              "      <td>IUFL5sUq0Fu7gN79f15EAg.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2WNp_NTYilaAGJMxTlUUHQ</td>\n",
              "      <td>lI3aba-4VAnqiQLUPGewNg</td>\n",
              "      <td></td>\n",
              "      <td>outside</td>\n",
              "      <td>2WNp_NTYilaAGJMxTlUUHQ.jpg</td>\n",
              "      <td>Amelia's</td>\n",
              "      <td>{'BikeParking': 'True', 'WiFi': 'u'free'', 'Re...</td>\n",
              "      <td>Cafes, Bakeries, Food, Coffee &amp; Tea, Restaurants</td>\n",
              "      <td>lI3aba-4VAnqiQLUPGewNg</td>\n",
              "      <td></td>\n",
              "      <td>outside</td>\n",
              "      <td>2WNp_NTYilaAGJMxTlUUHQ.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47995</th>\n",
              "      <td>Rkzj9PlYi7joFtdYZssHhQ</td>\n",
              "      <td>vstYOxnXc3Vcq9rl5S19uA</td>\n",
              "      <td></td>\n",
              "      <td>food</td>\n",
              "      <td>Rkzj9PlYi7joFtdYZssHhQ.jpg</td>\n",
              "      <td>Sangiovese Ristorante</td>\n",
              "      <td>{'RestaurantsAttire': 'u'casual'', 'Restaurant...</td>\n",
              "      <td>Italian, American (Traditional), Restaurants</td>\n",
              "      <td>vstYOxnXc3Vcq9rl5S19uA</td>\n",
              "      <td></td>\n",
              "      <td>food</td>\n",
              "      <td>Rkzj9PlYi7joFtdYZssHhQ.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47996</th>\n",
              "      <td>CO6MrzvuCjhSmP2g4Q_CKQ</td>\n",
              "      <td>HH9x7WcNQR3cnwkHo_YL0w</td>\n",
              "      <td>Turkey meatball (one with Spicy Cilantro and o...</td>\n",
              "      <td>food</td>\n",
              "      <td>CO6MrzvuCjhSmP2g4Q_CKQ.jpg</td>\n",
              "      <td>Mimi Blue Meatballs</td>\n",
              "      <td>{'WheelchairAccessible': 'True', 'RestaurantsA...</td>\n",
              "      <td>Restaurants, Italian, Breakfast &amp; Brunch, Amer...</td>\n",
              "      <td>HH9x7WcNQR3cnwkHo_YL0w</td>\n",
              "      <td>Turkey meatball (one with Spicy Cilantro and o...</td>\n",
              "      <td>food</td>\n",
              "      <td>CO6MrzvuCjhSmP2g4Q_CKQ.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47997</th>\n",
              "      <td>1nUnsphK9KMVjpzjjB67Sw</td>\n",
              "      <td>lzedq7Zh55nISP3z8RAw5g</td>\n",
              "      <td>Love their coffee cups.</td>\n",
              "      <td>drink</td>\n",
              "      <td>1nUnsphK9KMVjpzjjB67Sw.jpg</td>\n",
              "      <td>Post Commons</td>\n",
              "      <td>{'WiFi': ''free'', 'Ambience': '{'touristy': F...</td>\n",
              "      <td>Event Planning &amp; Services, Venues &amp; Event Spac...</td>\n",
              "      <td>lzedq7Zh55nISP3z8RAw5g</td>\n",
              "      <td>Love their coffee cups.</td>\n",
              "      <td>drink</td>\n",
              "      <td>1nUnsphK9KMVjpzjjB67Sw.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47998</th>\n",
              "      <td>BHnwKM1QW4y2hjn2CKcgGA</td>\n",
              "      <td>DNtXVS0xYn0n8Cscmj9JSg</td>\n",
              "      <td></td>\n",
              "      <td>inside</td>\n",
              "      <td>BHnwKM1QW4y2hjn2CKcgGA.jpg</td>\n",
              "      <td>Syberg's on Market</td>\n",
              "      <td>{'GoodForKids': 'True', 'RestaurantsReservatio...</td>\n",
              "      <td>Chicken Wings, Karaoke, Bars, American (Tradit...</td>\n",
              "      <td>DNtXVS0xYn0n8Cscmj9JSg</td>\n",
              "      <td></td>\n",
              "      <td>inside</td>\n",
              "      <td>BHnwKM1QW4y2hjn2CKcgGA.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47999</th>\n",
              "      <td>3rKDAtOINlXjTVtLGog47A</td>\n",
              "      <td>VCft2rBGhUtj3A5O37xe5w</td>\n",
              "      <td></td>\n",
              "      <td>food</td>\n",
              "      <td>3rKDAtOINlXjTVtLGog47A.jpg</td>\n",
              "      <td>Jack in the Box</td>\n",
              "      <td>{'NoiseLevel': 'u'average'', 'RestaurantsReser...</td>\n",
              "      <td>Burgers, Fast Food, American (New), Restaurant...</td>\n",
              "      <td>VCft2rBGhUtj3A5O37xe5w</td>\n",
              "      <td></td>\n",
              "      <td>food</td>\n",
              "      <td>3rKDAtOINlXjTVtLGog47A.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f9eb48b-e21e-438e-91b2-85e873655af7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f9eb48b-e21e-438e-91b2-85e873655af7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f9eb48b-e21e-438e-91b2-85e873655af7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     photo_id           business_id_x  \\\n",
              "0      9wTk1j-bB5UN17uiOeO9KA  EEVFMbJ6_YdbP3dHpHzmEg   \n",
              "1      LDJohic0bTD0oRknayxE1Q  EEVFMbJ6_YdbP3dHpHzmEg   \n",
              "2      96Qjf-5y9GVVf_cpZO8AVQ  EEVFMbJ6_YdbP3dHpHzmEg   \n",
              "3      IUFL5sUq0Fu7gN79f15EAg  EEVFMbJ6_YdbP3dHpHzmEg   \n",
              "4      2WNp_NTYilaAGJMxTlUUHQ  lI3aba-4VAnqiQLUPGewNg   \n",
              "...                       ...                     ...   \n",
              "47995  Rkzj9PlYi7joFtdYZssHhQ  vstYOxnXc3Vcq9rl5S19uA   \n",
              "47996  CO6MrzvuCjhSmP2g4Q_CKQ  HH9x7WcNQR3cnwkHo_YL0w   \n",
              "47997  1nUnsphK9KMVjpzjjB67Sw  lzedq7Zh55nISP3z8RAw5g   \n",
              "47998  BHnwKM1QW4y2hjn2CKcgGA  DNtXVS0xYn0n8Cscmj9JSg   \n",
              "47999  3rKDAtOINlXjTVtLGog47A  VCft2rBGhUtj3A5O37xe5w   \n",
              "\n",
              "                                               caption_x  label_x  \\\n",
              "0                                                           drink   \n",
              "1                                                            food   \n",
              "2                                                         outside   \n",
              "3                                                           drink   \n",
              "4                                                         outside   \n",
              "...                                                  ...      ...   \n",
              "47995                                                        food   \n",
              "47996  Turkey meatball (one with Spicy Cilantro and o...     food   \n",
              "47997                            Love their coffee cups.    drink   \n",
              "47998                                                      inside   \n",
              "47999                                                        food   \n",
              "\n",
              "                     photo_path_x                   name  \\\n",
              "0      9wTk1j-bB5UN17uiOeO9KA.jpg             Little Fox   \n",
              "1      LDJohic0bTD0oRknayxE1Q.jpg             Little Fox   \n",
              "2      96Qjf-5y9GVVf_cpZO8AVQ.jpg             Little Fox   \n",
              "3      IUFL5sUq0Fu7gN79f15EAg.jpg             Little Fox   \n",
              "4      2WNp_NTYilaAGJMxTlUUHQ.jpg               Amelia's   \n",
              "...                           ...                    ...   \n",
              "47995  Rkzj9PlYi7joFtdYZssHhQ.jpg  Sangiovese Ristorante   \n",
              "47996  CO6MrzvuCjhSmP2g4Q_CKQ.jpg    Mimi Blue Meatballs   \n",
              "47997  1nUnsphK9KMVjpzjjB67Sw.jpg           Post Commons   \n",
              "47998  BHnwKM1QW4y2hjn2CKcgGA.jpg     Syberg's on Market   \n",
              "47999  3rKDAtOINlXjTVtLGog47A.jpg        Jack in the Box   \n",
              "\n",
              "                                              attributes  \\\n",
              "0      {'BusinessAcceptsBitcoin': 'False', 'Restauran...   \n",
              "1      {'BusinessAcceptsBitcoin': 'False', 'Restauran...   \n",
              "2      {'BusinessAcceptsBitcoin': 'False', 'Restauran...   \n",
              "3      {'BusinessAcceptsBitcoin': 'False', 'Restauran...   \n",
              "4      {'BikeParking': 'True', 'WiFi': 'u'free'', 'Re...   \n",
              "...                                                  ...   \n",
              "47995  {'RestaurantsAttire': 'u'casual'', 'Restaurant...   \n",
              "47996  {'WheelchairAccessible': 'True', 'RestaurantsA...   \n",
              "47997  {'WiFi': ''free'', 'Ambience': '{'touristy': F...   \n",
              "47998  {'GoodForKids': 'True', 'RestaurantsReservatio...   \n",
              "47999  {'NoiseLevel': 'u'average'', 'RestaurantsReser...   \n",
              "\n",
              "                                              categories  \\\n",
              "0      Wine Bars, American (New), Restaurants, Bars, ...   \n",
              "1      Wine Bars, American (New), Restaurants, Bars, ...   \n",
              "2      Wine Bars, American (New), Restaurants, Bars, ...   \n",
              "3      Wine Bars, American (New), Restaurants, Bars, ...   \n",
              "4       Cafes, Bakeries, Food, Coffee & Tea, Restaurants   \n",
              "...                                                  ...   \n",
              "47995       Italian, American (Traditional), Restaurants   \n",
              "47996  Restaurants, Italian, Breakfast & Brunch, Amer...   \n",
              "47997  Event Planning & Services, Venues & Event Spac...   \n",
              "47998  Chicken Wings, Karaoke, Bars, American (Tradit...   \n",
              "47999  Burgers, Fast Food, American (New), Restaurant...   \n",
              "\n",
              "                business_id_y  \\\n",
              "0      EEVFMbJ6_YdbP3dHpHzmEg   \n",
              "1      EEVFMbJ6_YdbP3dHpHzmEg   \n",
              "2      EEVFMbJ6_YdbP3dHpHzmEg   \n",
              "3      EEVFMbJ6_YdbP3dHpHzmEg   \n",
              "4      lI3aba-4VAnqiQLUPGewNg   \n",
              "...                       ...   \n",
              "47995  vstYOxnXc3Vcq9rl5S19uA   \n",
              "47996  HH9x7WcNQR3cnwkHo_YL0w   \n",
              "47997  lzedq7Zh55nISP3z8RAw5g   \n",
              "47998  DNtXVS0xYn0n8Cscmj9JSg   \n",
              "47999  VCft2rBGhUtj3A5O37xe5w   \n",
              "\n",
              "                                               caption_y  label_y  \\\n",
              "0                                                           drink   \n",
              "1                                                            food   \n",
              "2                                                         outside   \n",
              "3                                                           drink   \n",
              "4                                                         outside   \n",
              "...                                                  ...      ...   \n",
              "47995                                                        food   \n",
              "47996  Turkey meatball (one with Spicy Cilantro and o...     food   \n",
              "47997                            Love their coffee cups.    drink   \n",
              "47998                                                      inside   \n",
              "47999                                                        food   \n",
              "\n",
              "                     photo_path_y  \n",
              "0      9wTk1j-bB5UN17uiOeO9KA.jpg  \n",
              "1      LDJohic0bTD0oRknayxE1Q.jpg  \n",
              "2      96Qjf-5y9GVVf_cpZO8AVQ.jpg  \n",
              "3      IUFL5sUq0Fu7gN79f15EAg.jpg  \n",
              "4      2WNp_NTYilaAGJMxTlUUHQ.jpg  \n",
              "...                           ...  \n",
              "47995  Rkzj9PlYi7joFtdYZssHhQ.jpg  \n",
              "47996  CO6MrzvuCjhSmP2g4Q_CKQ.jpg  \n",
              "47997  1nUnsphK9KMVjpzjjB67Sw.jpg  \n",
              "47998  BHnwKM1QW4y2hjn2CKcgGA.jpg  \n",
              "47999  3rKDAtOINlXjTVtLGog47A.jpg  \n",
              "\n",
              "[48000 rows x 12 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.merge(photos, on= 'photo_id')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "9nmKsRaC8Fu-",
        "outputId": "0a7eae50-e834-46e1-aee5-13006461ce8a"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'features'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-8b66c325f4a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'features'"
          ]
        }
      ],
      "source": [
        "X = df['features']\n",
        "y = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwoETmQz8Fx9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9TCzunf4Fr2"
      },
      "outputs": [],
      "source": [
        "tf.convert_to_tensor(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsPo2mS_4Iar"
      },
      "source": [
        "Second try on feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB_5Smd_4LGz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "\n",
        "vgg_conv = vgg16.VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(224, 224, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36eQ-zzt4N2g"
      },
      "outputs": [],
      "source": [
        "nTrain = 24000\n",
        "batch_size = 50\n",
        "# the defined shape is equal to the network output tensor shape\n",
        "train_features = np.zeros(shape=(nTrain, 7, 7, 512))\n",
        "train_labels = np.zeros(shape=(nTrain,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtZUljU04RUp"
      },
      "outputs": [],
      "source": [
        "# iterate through the batches of train images and labels\n",
        "for i, (inputs_batch, labels_batch) in enumerate(train_generator):\n",
        "    if i % 50 == 0:\n",
        "        print(i)\n",
        "    if i * batch_size >= nTrain:\n",
        "        break   \n",
        "    # pass the images through the network\n",
        "    features_batch = vgg_conv.predict(inputs_batch)\n",
        "    train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "    train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "# reshape train_features into vector       \n",
        "train_features_vec = np.reshape(train_features, (nTrain, 7 * 7 * 512))\n",
        "print(\"Train features: {}\".format(train_features_vec.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akwDSdGW4Tla"
      },
      "outputs": [],
      "source": [
        "for i, (inputs_batch, labels_batch) in enumerate(train_generator):\n",
        "    if i % 50 == 0:\n",
        "        print(i)\n",
        "    if i * batch_size >= nTrain:\n",
        "        break   \n",
        "    train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUj1QVe-4V2h"
      },
      "outputs": [],
      "source": [
        "np.save('train_features_vec', train_features_vec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GstSrBzl4YG5"
      },
      "outputs": [],
      "source": [
        "nVal = 6000\n",
        "validation_features = np.zeros(shape=(nVal, 7, 7, 512))\n",
        "validation_labels = np.zeros(shape=(nVal,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkNJ8AZx4h0N"
      },
      "outputs": [],
      "source": [
        "# iterate through the batches of validation images and labels\n",
        "for i, (inputs_batch, labels_batch) in enumerate(validation_generator):\n",
        "    if i % 50 == 0:\n",
        "        print(i)\n",
        "    if i * batch_size >= nVal:\n",
        "        break\n",
        "    features_batch = vgg_conv.predict(inputs_batch)\n",
        "    validation_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "    validation_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "\n",
        "# reshape validation_features into vector \n",
        "validation_features_vec = np.reshape(validation_features, (nVal, 7 * 7 * 512))\n",
        "print(\"Validation features: {}\".format(validation_features_vec.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80UQow4s4icL"
      },
      "outputs": [],
      "source": [
        "for i, (inputs_batch, labels_batch) in enumerate(validation_generator):\n",
        "    if i % 50 == 0:\n",
        "        print(i)\n",
        "    if i * batch_size >= nVal:\n",
        "        break\n",
        "    validation_labels[i * batch_size : (i + 1) * batch_size] = labels_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vyp-LcVn4mL8"
      },
      "outputs": [],
      "source": [
        "np.save('validation_features_vec', validation_features_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBPLz8rD4q0I"
      },
      "outputs": [],
      "source": [
        "train_features_vec = np.load('../input/features/train_features_vec.npy')\n",
        "validation_features_vec = np.load('../input/features/validation_features_vec.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVI8fdYW4r0d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import Sequential, optimizers\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_dim=7 * 7 * 512))\n",
        "model.add(Dense(128, activation='relu', input_dim=512))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_sX5sOW4vkH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# configure the model for training\n",
        "model.compile(optimizer=optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "# use the train and validation feature vectors\n",
        "history = model.fit(train_features_vec,\n",
        "                    train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(validation_features_vec,\n",
        "                                     validation_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7KVLcR-4wVc"
      },
      "outputs": [],
      "source": [
        "# use the train and validation feature vectors\n",
        "history = model.fit(train_features_vec,\n",
        "                    train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(validation_features_vec,\n",
        "                                     validation_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wsuj3QfC4yOq"
      },
      "outputs": [],
      "source": [
        "# get the list of all validation file names\n",
        "fnames = validation_generator.filenames\n",
        "\n",
        "# get the list of the corresponding classes\n",
        "ground_truth = validation_generator.classes[:300]\n",
        "\n",
        "# get the dictionary of classes\n",
        "label2index = validation_generator.class_indices\n",
        "\n",
        "# obtain the list of classes\n",
        "idx2label = list(label2index.keys())\n",
        "print(\"The list of classes: \", idx2label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLJAsti_41q5"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict_classes(validation_features_vec)\n",
        "prob = model.predict(validation_features_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6Zf_xn-42qw"
      },
      "outputs": [],
      "source": [
        "errors = np.where(predictions != ground_truth)[0]\n",
        "print(\"Number of errors = {}/{}\".format(len(errors),nVal))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hOm-C2W46AQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "import matplotlib.pyplot as plt\n",
        "for i in range(len(errors)):\n",
        "    pred_class = np.argmax(prob[errors[i]])\n",
        "    pred_label = idx2label[pred_class]\n",
        "    \n",
        "    print('Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
        "        fnames[errors[i]].split('/')[0],\n",
        "        pred_label,\n",
        "        prob[errors[i]][pred_class]))\n",
        "    \n",
        "    original = load_img('{}/{}'.format(photos_dir,fnames[errors[i]]))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(original)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6-N9cz_47Ub"
      },
      "source": [
        "Inception fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMZNQUgg46s1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer --  we have 4 classes\n",
        "predictions = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3XvUU2A5ACp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isYdZs445AFj"
      },
      "outputs": [],
      "source": [
        "totalTrain=33600\n",
        "totalVal=9600\n",
        "NUM_EPOCHS=10\n",
        "# train the model on the new data for a few epochs\n",
        "model.fit(train_generator,\n",
        "    steps_per_epoch=totalTrain // batch_size,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=totalVal // batch_size,\n",
        "    epochs=NUM_EPOCHS)\n",
        "\n",
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdEn23Da5AIr"
      },
      "outputs": [],
      "source": [
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    print(i, layer.name)\n",
        "\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:249]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUA6W53i5LFu"
      },
      "outputs": [],
      "source": [
        "totalTrain = 33600\n",
        "totalVal = 9600\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy',\n",
        "    metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "model.fit(train_generator,\n",
        "    steps_per_epoch=totalTrain // batch_size,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=totalVal // batch_size,\n",
        "    epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03Yl3CPA53s1"
      },
      "source": [
        "Resnet fine tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NXixHix55u_"
      },
      "outputs": [],
      "source": [
        "totalTrain=4000\n",
        "totalVal = 1000\n",
        "# initialize the initial learning rate, batch size, and number of\n",
        "# epochs to train for\n",
        "INIT_LR = 1e-4\n",
        "NUM_EPOCHS = 20\n",
        "# define the path to the serialized output model after training\n",
        "MODEL_PATH = \"label_detector.model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRLGyE-x56IG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "Y = photos['label']\n",
        "\n",
        "kf = KFold(n_splits = 5) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79BQDYKE6CIO"
      },
      "outputs": [],
      "source": [
        "idg = ImageDataGenerator(width_shift_range=0.1,\n",
        "                         height_shift_range=0.1,\n",
        "                         zoom_range=0.3,\n",
        "                         fill_mode='nearest',\n",
        "                         horizontal_flip = True,\n",
        "                         rescale=1./255)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjTlYu2q56Wf"
      },
      "outputs": [],
      "source": [
        "def get_model_name(k):\n",
        "    return 'model_'+str(k)+'.h5'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r15CMK0P6GNK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer --  we have 4 classes\n",
        "predictions = Dense(4, activation='softmax')(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fel042mr6Jmh"
      },
      "outputs": [],
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "batch_size = 50\n",
        "num_epochs=10\n",
        "photos_dir = '../input/photos/photos'\n",
        "nTrain = 48000\n",
        "save_dir = '/saved_models/'\n",
        "fold_var = 1\n",
        "\n",
        "for train_index, val_index in kf.split(np.zeros(len(photos)),Y):\n",
        "    training_data = photos.iloc[train_index]\n",
        "    validation_data = photos.iloc[val_index]\n",
        "    \n",
        "    train_data_generator = idg.flow_from_dataframe(photos[:40000], photos_dir, x_col = 'photo_path', y_col = 'label',\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical', shuffle=True)\n",
        "\n",
        "    valid_data_generator  = idg.flow_from_dataframe(photos[40000:46000],\n",
        "                                                  photos_dir, x_col = 'photo_path', y_col = 'label',\n",
        "                                                  target_size=(224, 224),\n",
        "                                                  batch_size=batch_size,color_mode=\"rgb\",\n",
        "                                                  class_mode='categorical', shuffle=True)\n",
        "    \n",
        "    # CREATE NEW MODEL\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    # COMPILE NEW MODEL\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "    # compile the model (should be done *after* setting layers to non-trainable)\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "                  metrics=[\"accuracy\"])\n",
        "    \n",
        "    # CREATE CALLBACKS\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
        "                                                  monitor='val_accuracy', verbose=1, \n",
        "                                                  save_best_only=True, mode='max')\n",
        "    callbacks_list = [checkpoint]\n",
        "    # There can be other callbacks, but just showing one because it involves the model name\n",
        "    # This saves the best model\n",
        "    # FIT THE MODEL\n",
        "    history = model.fit(train_data_generator,\n",
        "                      epochs=num_epochs,\n",
        "                      callbacks=callbacks_list,\n",
        "                      validation_data=valid_data_generator)\n",
        "    #PLOT HISTORY\n",
        "    #\t\t:\n",
        "    #\t\t:\n",
        "    \n",
        "    # LOAD BEST MODEL to evaluate the performance of the model\n",
        "    model.load_weights(\"/saved_models/model_\"+str(fold_var)+\".h5\")\n",
        "    \n",
        "    results = model.evaluate(valid_data_generator)\n",
        "    results = dict(zip(model.metrics_names,results))\n",
        "    \n",
        "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
        "    VALIDAITON_LOSS.append(results['loss'])\n",
        "    \n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "    fold_var += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV1we2BQ6MWs"
      },
      "outputs": [],
      "source": [
        "# initialize the training training data augmentation object\n",
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=25,\n",
        "\tzoom_range=0.1,\n",
        "\twidth_shift_range=0.1,\n",
        "\theight_shift_range=0.1,\n",
        "\tshear_range=0.2,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n",
        "# initialize the validation/testing data augmentation object (which\n",
        "# we'll be adding mean subtraction to)\n",
        "valAug = ImageDataGenerator()\n",
        "# define the ImageNet mean subtraction (in RGB order) and set the\n",
        "# the mean subtraction value for each of the data augmentation\n",
        "# objects\n",
        "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
        "trainAug.mean = mean\n",
        "valAug.mean = mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2QIjTWi6NMJ"
      },
      "outputs": [],
      "source": [
        "# load the ResNet-50 network, ensuring the head FC layer sets are left\n",
        "# off\n",
        "print(\"[INFO] preparing model...\")\n",
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
        "    input_tensor=Input(shape=(224, 224, 3)))\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(4, activation=\"softmax\")(headModel)\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the training process\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV25NZID6Qa-"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / NUM_EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "    metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "totalTrain=38400\n",
        "totalVal = 9600\n",
        "H = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=totalTrain // batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=totalVal // batch_size,\n",
        "    epochs=NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPzeYnLe6Ti5"
      },
      "outputs": [],
      "source": [
        "H = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=totalTrain // batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=totalVal // batch_size,\n",
        "    epochs=NUM_EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3STx0Chd6VdF"
      },
      "outputs": [],
      "source": [
        "testGen = datagen.flow_from_dataframe(small_photos[6000:],\n",
        "    photos_dir, x_col = 'photo_path', y_col = 'label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,color_mode=\"rgb\",\n",
        "    class_mode='categorical',\n",
        "    shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0F6g8xK6X-a"
      },
      "outputs": [],
      "source": [
        "model.save('resnet_labels.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz6694af6aME"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('../input/trained-model-resnet/resnet_labels.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztqhhf4-6cOo"
      },
      "outputs": [],
      "source": [
        "INIT_LR = 1e-4\n",
        "NUM_EPOCHS = 1\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / NUM_EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "    metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOosAW9t6c73"
      },
      "outputs": [],
      "source": [
        "totalTrain = 33600\n",
        "totalVal = 9600\n",
        "model.fit(train_generator,\n",
        "    steps_per_epoch=totalTrain // batch_size,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=totalVal // batch_size,\n",
        "    epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBGhVado6fQu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "totalTest=6600\n",
        "# reset the testing generator and then use our trained model to\n",
        "# make predictions on the data\n",
        "print(\"[INFO] evaluating network...\")\n",
        "test_generator.reset()\n",
        "predIdxs = model.predict_generator(test_generator,\n",
        "\tsteps=(totalTest // batch_size) + 1)\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(test_generator.classes, predIdxs,\n",
        "\ttarget_names=test_generator.class_indices.keys()))\n",
        "# serialize the model to disk\n",
        "#print(\"[INFO] saving model...\")\n",
        "#MODEL_PATH = \"inceptionv3.model\"\n",
        "#model.save(MODEL_PATH, save_format=\"h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpkTEZey6jBg"
      },
      "outputs": [],
      "source": [
        "# plot the training loss and accuracy\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YTtRQKi6kIQ"
      },
      "source": [
        "Ambience classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r1P0Xxo6l9Y"
      },
      "outputs": [],
      "source": [
        "ambiences = ['touristy', 'hipster', 'romantic', 'intimate', 'trendy', 'upscale', 'classy', 'casual']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuVZBMqc6qoC"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "for colname in ambiences:\n",
        "    df[colname]=0\n",
        "    print('working on '+colname)\n",
        "    for row in df.itertuples():\n",
        "      if row.attributes != None:\n",
        "          d = dict(row.attributes)\n",
        "          try:\n",
        "            #print(ast.literal_eval(d['Ambience']))\n",
        "            if ast.literal_eval(d['Ambience'])!= None:\n",
        "                try:\n",
        "                  if ast.literal_eval(d['Ambience'])[colname] == None:\n",
        "                    df[colname][row.Index] = 0\n",
        "                  else:  \n",
        "                    df[colname][row.Index] = int(ast.literal_eval(d['Ambience'])[colname])\n",
        "                except KeyError:\n",
        "                    continue\n",
        "          except KeyError:\n",
        "                continue "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCHiJ3tE63yl"
      },
      "outputs": [],
      "source": [
        "df = df[df['label'] == 'inside']\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVJIYC8D650B"
      },
      "outputs": [],
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255.)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "columns=ambiences\n",
        "nTrain=48000 \n",
        "photos_dir = '../input/photos/photos'\n",
        "\n",
        "\n",
        "train_generator=datagen.flow_from_dataframe(dataframe=df[:int(nTrain*0.7)],\n",
        "                                            directory=photos_dir,\n",
        "                                            x_col='photo_path',\n",
        "                                            y_col=columns,\n",
        "                                            batch_size=50,\n",
        "                                            seed=42,\n",
        "                                            shuffle=True,\n",
        "                                            class_mode=\"raw\",\n",
        "                                            target_size=(224,224))\n",
        "valid_generator=test_datagen.flow_from_dataframe(dataframe=df[int(nTrain*0.7):int(nTrain*0.9)],\n",
        "                                                 directory=photos_dir,\n",
        "                                                 x_col='photo_path',y_col=columns,\n",
        "                                                 batch_size=50,seed=42,shuffle=True,\n",
        "                                                 class_mode=\"raw\",\n",
        "                                                 target_size=(224,224))\n",
        "'''test_generator=test_datagen.flow_from_dataframe(dataframe=df[int(nTrain*0.9):],\n",
        "                                                directory=photos_dir,\n",
        "                                                x_col='photo_path',\n",
        "                                                batch_size=1,\n",
        "                                                seed=42,\n",
        "                                                shuffle=False,\n",
        "                                                class_mode=None,\n",
        "                                                target_size=(256,256))'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fepmTKa69zU"
      },
      "source": [
        "Inception for ambience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Uh_H8Zq67sO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer --  we have 4 classes\n",
        "predictions = Dense(8, activation='sigmoid')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LT1kVg327CEv"
      },
      "outputs": [],
      "source": [
        "totalTrain = 33600\n",
        "totalVal = 9600\n",
        "batch_size = 50\n",
        "STEP_SIZE_TRAIN = totalTrain // batch_size\n",
        "STEP_SIZE_VALID = totalVal // batch_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjo3Y7pX7Cwd"
      },
      "outputs": [],
      "source": [
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
        "    metrics=[tf.keras.metrics.Precision(),'accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxQzBeJx7FK2"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU8Y1bol7HJb"
      },
      "outputs": [],
      "source": [
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:249]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylKLbDef7K1k"
      },
      "outputs": [],
      "source": [
        "# we need to recompile the model for these modifications to take effect\n",
        "# we use SGD with a low learning rate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow as tf\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='binary_crossentropy',\n",
        "    metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
        "# alongside the top Dense layers\n",
        "model.fit(train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=7\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICwXjjt-7rlZ"
      },
      "source": [
        "resnet for ambience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubEbrcoZ7v9T"
      },
      "outputs": [],
      "source": [
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False,\n",
        "                     input_tensor=Input(shape=(224, 224, 3)))\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(512, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(8, activation=\"sigmoid\")(headModel)\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the training process\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "model.compile(optimizers.RMSprop(lr=0.0001, decay=1e-6),loss=\"binary_crossentropy\",metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5ohvqk77xPG"
      },
      "outputs": [],
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=7\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3pZljii7zNx"
      },
      "source": [
        "Feature extraction for ambience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja6lduvq72Jn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import vgg16\n",
        "\n",
        "vgg_conv = vgg16.VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyGM5Mfv75LS"
      },
      "outputs": [],
      "source": [
        "nTrain = 14000\n",
        "batch_size = 50\n",
        "# the defined shape is equal to the network output tensor shape\n",
        "train_features = np.zeros(shape=(nTrain, 7, 7, 512))\n",
        "train_labels = np.zeros(shape=(nTrain,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTjsXjya752v"
      },
      "outputs": [],
      "source": [
        "# iterate through the batches of train images and labels\n",
        "for i, (inputs_batch, labels_batch) in enumerate(train_generator):\n",
        "    if i % 50 == 0:\n",
        "        print(i)\n",
        "    if i * batch_size >= nTrain:\n",
        "        break   \n",
        "    # pass the images through the network\n",
        "    features_batch = vgg_conv.predict(inputs_batch)\n",
        "    train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "    train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "# reshape train_features into vector       \n",
        "train_features_vec = np.reshape(train_features, (nTrain, 7 * 7 * 512))\n",
        "print(\"Train features: {}\".format(train_features_vec.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYL9Iu3t774F"
      },
      "outputs": [],
      "source": [
        "np.save('train_features', train_features)\n",
        "np.save('train_labels', train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63SUrFIs793r"
      },
      "outputs": [],
      "source": [
        "nVal = 4000\n",
        "validation_features = np.zeros(shape=(nVal, 7, 7, 512))\n",
        "validation_labels = np.zeros(shape=(nVal,8))\n",
        "# iterate through the batches of validation images and labels\n",
        "for i, (inputs_batch, labels_batch) in enumerate(valid_generator):\n",
        "    if i % 50 == 0:\n",
        "        print(i)\n",
        "    if i * batch_size >= nVal:\n",
        "        break\n",
        "    features_batch = vgg_conv.predict(inputs_batch)\n",
        "    validation_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
        "    validation_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
        "\n",
        "# reshape validation_features into vector \n",
        "validation_features_vec = np.reshape(validation_features, (nVal, 7 * 7 * 512))\n",
        "print(\"Validation features: {}\".format(validation_features_vec.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hlTN3KH7_it"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import Sequential, optimizers\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_dim=7 * 7 * 512))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3rkaY0u8A4m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# configure the model for training\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "\n",
        "# use the train and validation feature vectors\n",
        "history = model.fit(train_features_vec,\n",
        "                    train_labels,\n",
        "                    epochs=10,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(validation_features_vec,\n",
        "                                     validation_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIaJO5VO8DX9"
      },
      "outputs": [],
      "source": [
        "# use the train and validation feature vectors\n",
        "history = model.fit(train_features_vec,\n",
        "                    train_labels,\n",
        "                    epochs=20,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(validation_features_vec,\n",
        "                                     validation_labels))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "НИС.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}